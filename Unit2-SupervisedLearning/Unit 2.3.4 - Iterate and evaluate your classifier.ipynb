{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here down to the markdown cell that reads: 'Unit 2.3.4' is an exact copy of Unit 2.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive\n",
       "0                           Wow... Loved this place.         1\n",
       "1                                 Crust is not good.         0\n",
       "2          Not tasty and the texture was just nasty.         0\n",
       "3  Stopped by during the late May bank holiday of...         1\n",
       "4  The selection on the menu was great and so wer...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'C:\\Users\\Toshiba P55w\\sentiment labelled sentences\\sentiment labelled sentences\\yelp_labelled.txt'\n",
    "yelp = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "yelp.columns = ['Review', 'Positive']\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: build a naive bayes classifier that predicts whether a review is positive or negative\n",
    "\n",
    "## Feature engineering overview:\n",
    "I am going to identify words that are used a lot more in one type of review than the other. For each one of these words there will be a feature that shows whether the review contains the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>[wow, loved, this, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>[crust, is, not, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive  \\\n",
       "0                           Wow... Loved this place.         1   \n",
       "1                                 Crust is not good.         0   \n",
       "2          Not tasty and the texture was just nasty.         0   \n",
       "3  Stopped by during the late May bank holiday of...         1   \n",
       "4  The selection on the menu was great and so wer...         1   \n",
       "\n",
       "                                           Word_list  \n",
       "0                          [wow, loved, this, place]  \n",
       "1                             [crust, is, not, good]  \n",
       "2  [not, tasty, and, the, texture, was, just, nasty]  \n",
       "3  [stopped, by, during, the, late, may, bank, ho...  \n",
       "4  [the, selection, on, the, menu, was, great, an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn every review into a list of words\n",
    "yelp['Word_list'] = yelp['Review'].str.lower().str.replace(r'[^\\w\\s]', '',).str.strip().str.split()\n",
    "\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "positive_words = reduce(lambda x,y: x+y ,yelp[yelp['Positive']==1]['Word_list'] )\n",
    "negative_words = reduce(lambda x,y: x+y ,yelp[yelp['Positive']==0]['Word_list'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count_positive_dct = Counter(positive_words)\n",
    "\n",
    "word_count_negative_dct = Counter(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Positive_count</th>\n",
       "      <th>Negative_count</th>\n",
       "      <th>Total_count</th>\n",
       "      <th>P_ratio</th>\n",
       "      <th>N_ratio</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>every</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wasnt</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>either</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>loved</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>dont</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Positive_count  Negative_count  Total_count  P_ratio  N_ratio  \\\n",
       "3     every               8               1            9   0.8889   0.1111   \n",
       "18    wasnt               0              13           13   0.0000   1.0000   \n",
       "49   either               0               6            6   0.0000   1.0000   \n",
       "50    loved              10               0           10   1.0000   0.0000   \n",
       "134    dont               3              25           28   0.1071   0.8929   \n",
       "\n",
       "    Sentiment  \n",
       "3    Positive  \n",
       "18   Negative  \n",
       "49   Negative  \n",
       "50   Positive  \n",
       "134  Negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(list(word_count_positive_dct.keys())+list(word_count_negative_dct.keys()))\n",
    "word_counts = pd.DataFrame(list(all_words), columns=['Word'])\n",
    "\n",
    "word_counts['Positive_count'] = word_counts['Word'].apply(lambda x: word_count_positive_dct.get(x, 0))\n",
    "word_counts['Negative_count'] = word_counts['Word'].apply(lambda x: word_count_negative_dct.get(x, 0))\n",
    "word_counts['Total_count'] = word_counts['Positive_count'] + word_counts['Negative_count']\n",
    "\n",
    "# ratio of reviews word is in that are positive\n",
    "word_counts['P_ratio'] = round(word_counts['Positive_count']/(word_counts['Positive_count'] + word_counts['Negative_count']),4)\n",
    "\n",
    "# ratio of reviews word is in that are negative\n",
    "word_counts['N_ratio'] = round(word_counts['Negative_count']/(word_counts['Positive_count'] + word_counts['Negative_count']),4)\n",
    "\n",
    "word_counts['Sentiment'] = np.where(word_counts['Negative_count'] > word_counts['Positive_count'], 'Negative', 'Positive')\n",
    "\n",
    "# use words that show up in one type of review at a minimum ratio and that show up in all review a minimum number of times\n",
    "min_ratio = .8\n",
    "min_total_count = 5\n",
    "keywords_df = word_counts[((word_counts['P_ratio'] > min_ratio) | (word_counts['N_ratio'] > min_ratio)) &\n",
    "                          (word_counts['Total_count'] > min_total_count)\n",
    "                         ]\n",
    "\n",
    "keywords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make feature for each keyword\n",
    "keywords = list(keywords_df['Word'])\n",
    "\n",
    "for key in keywords:    \n",
    "    yelp[str(key)] = yelp['Word_list'].apply(lambda x: key in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.792\n"
     ]
    }
   ],
   "source": [
    "data = yelp[keywords]\n",
    "target = yelp['Positive']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"accuracy : {}\".format(\n",
    "    (target == y_pred).sum()/data.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test classifier on one of the other datasets to see how well these kinds of classifiers translate from one context to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive\n",
       "0  So there is no way for me to plug it in here i...         0\n",
       "1                        Good case, Excellent value.         1\n",
       "2                             Great for the jawbone.         1\n",
       "3  Tied to charger for conversations lasting more...         0\n",
       "4                                  The mic is great.         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_path = r'C:\\Users\\Toshiba P55w\\sentiment labelled sentences\\sentiment labelled sentences\\amazon_cells_labelled.txt'\n",
    "\n",
    "amzn = pd.read_csv(amzn_path, delimiter='\\t', header=None)\n",
    "amzn.columns = ['Review', 'Positive']\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[so, there, is, no, way, for, me, to, plug, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive  \\\n",
       "0  So there is no way for me to plug it in here i...         0   \n",
       "1                        Good case, Excellent value.         1   \n",
       "2                             Great for the jawbone.         1   \n",
       "3  Tied to charger for conversations lasting more...         0   \n",
       "4                                  The mic is great.         1   \n",
       "\n",
       "                                           Word_list  \n",
       "0  [so, there, is, no, way, for, me, to, plug, it...  \n",
       "1                     [good, case, excellent, value]  \n",
       "2                         [great, for, the, jawbone]  \n",
       "3  [tied, to, charger, for, conversations, lastin...  \n",
       "4                              [the, mic, is, great]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn['Word_list'] = amzn['Review'].str.lower().str.replace(r'[^\\w\\s]', '',).str.strip().str.split()\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keywords:\n",
    "    amzn[str(key)] = amzn['Word_list'].apply(lambda x: key in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.686\n"
     ]
    }
   ],
   "source": [
    "amzn_data = amzn[keywords]\n",
    "amzn_target = amzn['Positive']\n",
    "\n",
    "amzn_y_pred = bnb.predict(amzn_data)\n",
    "\n",
    "print(\"accuracy : {}\".format(\n",
    "    (amzn_target == amzn_y_pred).sum()/data.shape[0]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 2.3.4 - Iterate and evaluate your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "Do any of your classifiers seem to overfit?\n",
    "Which seem to perform the best? Why?\n",
    "Which features seemed to be most impactful to performance?\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at classifiers performance in more detail:\n",
    "\n",
    "- cross validate\n",
    "- sensitivity (true positive rate)\n",
    "- specificity (true negative rate)\n",
    "- precision  (positive predictive value)\n",
    "- negative predictive value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81,  0.76,  0.82,  0.75,  0.76,  0.77,  0.75,  0.83,  0.76,  0.83])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a binary confusion matrix class with all the metrics we want\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class Binary_confusion_matrix():\n",
    "    \n",
    "    def __init__(self, target, y_pred):\n",
    "        self.target = target\n",
    "        self.y_pred = y_pred\n",
    "        self.cm = confusion_matrix(target, y_pred, labels=[1, 0])\n",
    "        self.df = pd.DataFrame(self.cm, columns=['pred_true','pred_false'], index=['actual_true', 'actual_false'])\n",
    "        self.tp, self.fn, self.fp, self.tn = self.cm.ravel()\n",
    "        self.sensitivity = self.tp/(self.tp+self.fn)\n",
    "        self.specificity = self.tn/(self.tn+self.fp)\n",
    "        self.precision = self.tp/(self.tp+self.fp)\n",
    "        self.neg_pred_val = self.tn/(self.tn+self.fn)\n",
    "        self.accuracy = (self.tp+self.tn)/(self.tp+self.tn+self.fp+self.fn)\n",
    "    \n",
    "    def display_metrics(self):\n",
    "        metrics_string = 'Accuracy = {}\\nSensitivity = {}\\nSpecificity = {}\\nPrecision = {}\\nnegative predictive value = {}\\n'.format(self.accuracy, self.sensitivity, self.specificity, self.precision, self.neg_pred_val)\n",
    "        print(metrics_string)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.792\n",
      "Sensitivity = 0.934\n",
      "Specificity = 0.65\n",
      "Precision = 0.7274143302180686\n",
      "negative predictive value = 0.9078212290502793\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_true</th>\n",
       "      <th>pred_false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_true</th>\n",
       "      <td>467</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_false</th>\n",
       "      <td>175</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred_true  pred_false\n",
       "actual_true         467          33\n",
       "actual_false        175         325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run instantiate binary confusion metrics with target and prediction data.\n",
    "cm = Binary_confusion_matrix(target, y_pred)\n",
    "\n",
    "# look at matrix and metrics\n",
    "cm.display_metrics()\n",
    "cm.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the confusion matrix that there are many more false positives than false negatives. Let's explore why this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Word_list</th>\n",
       "      <th>every</th>\n",
       "      <th>wasnt</th>\n",
       "      <th>either</th>\n",
       "      <th>loved</th>\n",
       "      <th>dont</th>\n",
       "      <th>awesome</th>\n",
       "      <th>before</th>\n",
       "      <th>...</th>\n",
       "      <th>twice</th>\n",
       "      <th>bland</th>\n",
       "      <th>impressed</th>\n",
       "      <th>getting</th>\n",
       "      <th>attentive</th>\n",
       "      <th>family</th>\n",
       "      <th>atmosphere</th>\n",
       "      <th>beer</th>\n",
       "      <th>predicted</th>\n",
       "      <th>kw_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>[wow, loved, this, place]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>[crust, is, not, good]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive  \\\n",
       "0                           Wow... Loved this place.         1   \n",
       "1                                 Crust is not good.         0   \n",
       "2          Not tasty and the texture was just nasty.         0   \n",
       "3  Stopped by during the late May bank holiday of...         1   \n",
       "4  The selection on the menu was great and so wer...         1   \n",
       "\n",
       "                                           Word_list  every  wasnt  either  \\\n",
       "0                          [wow, loved, this, place]  False  False   False   \n",
       "1                             [crust, is, not, good]  False  False   False   \n",
       "2  [not, tasty, and, the, texture, was, just, nasty]  False  False   False   \n",
       "3  [stopped, by, during, the, late, may, bank, ho...  False  False   False   \n",
       "4  [the, selection, on, the, menu, was, great, an...  False  False   False   \n",
       "\n",
       "   loved   dont  awesome  before    ...     twice  bland  impressed  getting  \\\n",
       "0   True  False    False   False    ...     False  False      False    False   \n",
       "1  False  False    False   False    ...     False  False      False    False   \n",
       "2  False  False    False   False    ...     False  False      False    False   \n",
       "3   True  False    False   False    ...     False  False      False    False   \n",
       "4  False  False    False   False    ...     False  False      False    False   \n",
       "\n",
       "   attentive  family  atmosphere   beer  predicted  kw_count  \n",
       "0      False   False       False  False          1         1  \n",
       "1      False   False       False  False          0         1  \n",
       "2      False   False       False  False          0         1  \n",
       "3      False   False       False  False          1         1  \n",
       "4      False   False       False  False          1         2  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add prediction result to dataframe\n",
    "yelp['predicted'] = y_pred\n",
    "\n",
    "# count how many keywords each review has\n",
    "yelp['kw_count'] = yelp[keywords].sum(axis=1)\n",
    "\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    168\n",
       "1      5\n",
       "2      2\n",
       "Name: kw_count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives = yelp[(yelp['Positive']==0) & yelp['predicted'] == 1]\n",
    "\n",
    "false_positives['kw_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    376\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_kw = yelp[yelp.kw_count==0]\n",
    "\n",
    "zero_kw.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    42\n",
       "Positive    26\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of our false positives contain 0 keywords in their review... and all of our reviews with no keywords were predicted to be positive. This is likely because there is an imbalance of negative and positive keywords. Lets add more postive keywords to our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make an equal number of positive and negative keywords\n",
    "\n",
    "# get the top 42 positive keywords (with total occurences > 5)\n",
    "top_42_pos = word_counts[word_counts['Total_count'] > 5].sort_values(by='P_ratio', ascending=False)[:42]\n",
    "\n",
    "# add them to the keywords list\n",
    "keywords += list(top_42_pos['Word'])\n",
    "\n",
    "# get rid of redundancies\n",
    "keywords = list(set(keywords))\n",
    "\n",
    "# make each keyword a feature\n",
    "for key in keywords:\n",
    "    yelp[str(key)] = yelp['Word_list'].apply(lambda x: key in x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.824\n"
     ]
    }
   ],
   "source": [
    "#refit our model\n",
    "\n",
    "data = yelp[keywords]\n",
    "target = yelp['Positive']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"accuracy : {}\".format(\n",
    "    (target == y_pred).sum()/data.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.824\n",
      "Sensitivity = 0.684\n",
      "Specificity = 0.964\n",
      "Precision = 0.95\n",
      "negative predictive value = 0.753125\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_true</th>\n",
       "      <th>pred_false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_true</th>\n",
       "      <td>342</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_false</th>\n",
       "      <td>18</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred_true  pred_false\n",
       "actual_true         342         158\n",
       "actual_false         18         482"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = Binary_confusion_matrix(target, y_pred)\n",
    "cm.display_metrics()\n",
    "cm.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is more accurate overall, but now we have the opposite problem as before. There are many more false negatives than false positives. We could just keep adding key words, but then our model would eventually be overfit (if it isn't already). A possible next step could be to look for other features besides keywords that could help classify sentiment (length of review, use of certain punctuation or capitalization...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
