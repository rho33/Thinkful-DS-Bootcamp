{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:31:55.292979Z",
     "start_time": "2019-02-20T22:31:55.280988Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, SpectralClustering, AffinityPropagation, MeanShift\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "**Pick Set of Texts**\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "\n",
    "**Create Series of Clusters**\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "\n",
    "**Unsupervised Feature Generation + Model**\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "\n",
    "**Compare clusters on Test Set**\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "\n",
    "**Writing**\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:31:55.400936Z",
     "start_time": "2019-02-20T22:31:55.296977Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def clean_sentence(text):\n",
    "    '''combines specific sentence cleaning operations for this project'''\n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    text = re.sub(r'CHAPTER \\d+','',text)\n",
    "    \n",
    "    text = re.sub(r'Actus \\w+','',text)\n",
    "    \n",
    "    if text == text.upper():\n",
    "        text = ''\n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:31:55.486947Z",
     "start_time": "2019-02-20T22:31:55.405915Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pickle_obj(obj, mode='wb', name=None):\n",
    "    '''convenience function for pickling objects that take a long time to make from scratch'''\n",
    "    now = datetime.datetime.now()\n",
    "    if not name:\n",
    "        name = 'pickle_file_{}-{}-{}_{}.pickle'.format(now.month, now.day, now.year, now.microsecond)\n",
    "    else:\n",
    "        name = '{}_{}-{}-{}_{}.pickle'.format(name, now.month, now.day, now.year, now.microsecond)\n",
    "    \n",
    "    print('opening...')\n",
    "    file = open(name, mode)\n",
    "    print('dumping...')\n",
    "    pickle.dump(obj, file)\n",
    "    print('closing')\n",
    "    file.close()\n",
    "    \n",
    "    print('File Pickled, file name: {}'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:31:55.600518Z",
     "start_time": "2019-02-20T22:31:55.491917Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pickle_load(name):\n",
    "    '''convenience function for loading pickled object(s) from file'''\n",
    "    file = open(name, 'rb')\n",
    "    obj = pickle.load(file)\n",
    "    file.close()\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:31:55.876041Z",
     "start_time": "2019-02-20T22:31:55.603514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:31:55.886037Z",
     "start_time": "2019-02-20T22:31:55.879039Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# These are the 10 texts that will be used in this assignment\n",
    "texts = [\n",
    " 'austen-persuasion.txt',\n",
    " 'blake-poems.txt',\n",
    " 'bryant-stories.txt',\n",
    " 'burgess-busterbrown.txt',\n",
    " 'carroll-alice.txt',\n",
    " 'chesterton-thursday.txt',\n",
    " 'edgeworth-parents.txt',\n",
    " 'melville-moby_dick.txt',\n",
    " 'shakespeare-macbeth.txt',   \n",
    " 'whitman-leaves.txt']\n",
    "\n",
    "# list of authors\n",
    "authors = [text[:text.index('-')].title() for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T01:25:12.580239Z",
     "start_time": "2019-02-23T01:25:12.574226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:46:16.738454Z",
     "start_time": "2019-02-20T22:46:16.729459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'animal',\n",
       " 'is',\n",
       " 'named',\n",
       " 'from',\n",
       " 'roundness',\n",
       " 'or',\n",
       " 'rolling',\n",
       " ';',\n",
       " 'for',\n",
       " 'in',\n",
       " 'Dan',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.paras('melville-moby_dick.txt')[5][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:50:33.204111Z",
     "start_time": "2019-02-20T22:50:25.747500Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Group each text into 100 paragraph sections. Grouping into chapters would've been nicer but this was much easier.\n",
    "\n",
    "para_groups = []\n",
    "para_authors = []\n",
    "for i, text in enumerate(texts):\n",
    "    \n",
    "    # get each text as list of paragraphs. first paragraph is always title so slice it off\n",
    "    paras = gutenberg.paras(text)[1:]\n",
    "    \n",
    "    # number of groups of paragraphs that will be made for this particular text.\n",
    "    n_groups = len(paras)//100+1\n",
    "    \n",
    "    # divide the big paragraph list into lists of 100 paragraphs \n",
    "    for j in range(n_groups):\n",
    "        #make list of 100 paragraphs\n",
    "        para_group = paras[j*100:(j+1)*100]\n",
    "        \n",
    "        # clean each sentence within each paragraph of para_group with clean_sentence utility function\n",
    "        para_group = [clean_sentence(' '.join(sent)) for para in para_group for sent in para]\n",
    "        \n",
    "        # join para_group to one big string and append to para_groups\n",
    "        para_groups.append(' '.join(para_group))\n",
    "        \n",
    "        # append author of the group of paragraphs to para_authors so we can keep track of who authored which group\n",
    "        para_authors.append(authors[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:53:52.858332Z",
     "start_time": "2019-02-20T22:53:52.833331Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Sir Walter Elliot , of Kellynch Hall , in Som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Lady Russell , convinced that Anne would not b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austen</td>\n",
       "      <td>The morning hours of the Cottage were always l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austen</td>\n",
       "      <td>The surprise of finding himself almost alone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austen</td>\n",
       "      <td>The Miss Musgroves agreed to it ; and having a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author                                               text\n",
       "0  Austen   Sir Walter Elliot , of Kellynch Hall , in Som...\n",
       "1  Austen  Lady Russell , convinced that Anne would not b...\n",
       "2  Austen  The morning hours of the Cottage were always l...\n",
       "3  Austen  The surprise of finding himself almost alone w...\n",
       "4  Austen  The Miss Musgroves agreed to it ; and having a..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make df using our para_groups and para_authors lists\n",
    "df = pd.DataFrame()\n",
    "df['author'] = para_authors\n",
    "df['text'] = para_groups\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:57:49.254098Z",
     "start_time": "2019-02-20T22:57:46.448868Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a column that converts the text into lemmas. This can take 5-10 min. so series was pickled \n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def lemma_string(text):\n",
    "    '''converts string into list of lemmas, and then joins the list back into a string'''\n",
    "    nlp = spacy.load('en')\n",
    "    lemma_list = []\n",
    "    for token in nlp(text):\n",
    "    \n",
    "        if token.is_punct or token.is_stop or token.lemma_ == '-PRON-':\n",
    "             # if token is stop word, punctuation, or pronoun then don't take the lemma, just append the token. \n",
    "            lemma_list.append(str(token))\n",
    "        else:\n",
    "            # Otherwise append lemma\n",
    "            lemma_list.append(token.lemma_)\n",
    "            \n",
    "    lemma_string =  ' '.join(lemma_list)\n",
    "    return lemma_string\n",
    "\n",
    "# df['lemmas'] = df['text'].apply(lemma_string)\n",
    "\n",
    "# pickle_obj(list(df['lemmas']), name='gutenberg_para_lemmas')\n",
    "\n",
    "# TAKES 5-10 MIN. Get from gutenberg_para_lemmas_1-12-2019_774761.pickle\n",
    "\n",
    "df['lemmas'] = pickle_load('gutenberg_para_lemmas_1-12-2019_774761.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T22:59:27.048292Z",
     "start_time": "2019-02-20T22:59:27.026305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Sir Walter Elliot , of Kellynch Hall , in Som...</td>\n",
       "      <td>sir walter elliot , of kellynch hall , in so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author                                               text  \\\n",
       "0  Austen   Sir Walter Elliot , of Kellynch Hall , in Som...   \n",
       "\n",
       "                                              lemmas  \n",
       "0    sir walter elliot , of kellynch hall , in so...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T23:21:16.716317Z",
     "start_time": "2019-02-20T23:21:16.643360Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austen</td>\n",
       "      <td>The surprise of finding himself almost alone w...</td>\n",
       "      <td>the surprise of find himself almost alone with...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austen</td>\n",
       "      <td>At last , Lady Russell drew back her head . \" ...</td>\n",
       "      <td>at last , lady russell draw back her head . \" ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Anne smiled , and let it pass . It was too ple...</td>\n",
       "      <td>anne smile , and let it pass . It was too plea...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bryant</td>\n",
       "      <td>\" You are the biggest thing on the land , Brot...</td>\n",
       "      <td>\" You are the big thing on the land , brother ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bryant</td>\n",
       "      <td>One day a Brahmin was walking along a country ...</td>\n",
       "      <td>one day a brahmin was walk along a country roa...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author                                               text  \\\n",
       "0  Austen  The surprise of finding himself almost alone w...   \n",
       "1  Austen  At last , Lady Russell drew back her head . \" ...   \n",
       "2  Austen  Anne smiled , and let it pass . It was too ple...   \n",
       "3  Bryant  \" You are the biggest thing on the land , Brot...   \n",
       "4  Bryant  One day a Brahmin was walking along a country ...   \n",
       "\n",
       "                                              lemmas  original_index  \n",
       "0  the surprise of find himself almost alone with...               3  \n",
       "1  at last , lady russell draw back her head . \" ...               7  \n",
       "2  anne smile , and let it pass . It was too plea...              10  \n",
       "3  \" You are the big thing on the land , brother ...              16  \n",
       "4  one day a brahmin was walk along a country roa...              20  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split df into training and test dataframes\n",
    "test_size = .25\n",
    "\n",
    "# save original index\n",
    "df['original_index'] = df.index\n",
    "\n",
    "train_df = df.sample(frac=1-test_size ,random_state=33)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# re-index training and test dataframes\n",
    "train_df.index = range(len(train_df))\n",
    "test_df.index = range(len(test_df))\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T06:32:19.044684Z",
     "start_time": "2019-01-13T06:32:18.962061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edgeworth      26\n",
       "Melville       24\n",
       "Whitman        20\n",
       "Chesterton     11\n",
       "Austen          8\n",
       "Bryant          8\n",
       "Shakespeare     5\n",
       "Carroll         5\n",
       "Blake           3\n",
       "Burgess         2\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf and LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T00:08:36.491738Z",
     "start_time": "2019-02-21T00:08:35.578051Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True, #we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "train_tfidf = vectorizer.fit_transform(train_df['lemmas'])\n",
    "test_tfidf = vectorizer.transform(test_df['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T20:03:51.136920Z",
     "start_time": "2019-02-22T20:03:51.051969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>15th</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>1791</th>\n",
       "      <th>18</th>\n",
       "      <th>1825</th>\n",
       "      <th>1836</th>\n",
       "      <th>1839</th>\n",
       "      <th>...</th>\n",
       "      <th>yon</th>\n",
       "      <th>yonder</th>\n",
       "      <th>yong</th>\n",
       "      <th>yore</th>\n",
       "      <th>york</th>\n",
       "      <th>youngster</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zay</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoological</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057411</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10   11   12   13   14   15  15th   16   17  1791   18  1825  1836  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0   0.0   \n",
       "\n",
       "       1839     ...           yon    yonder  yong  yore      york  youngster  \\\n",
       "0  0.008964     ...      0.000000  0.000000   0.0   0.0  0.008407        0.0   \n",
       "1  0.000000     ...      0.000000  0.010123   0.0   0.0  0.000000        0.0   \n",
       "2  0.000000     ...      0.000000  0.000000   0.0   0.0  0.000000        0.0   \n",
       "3  0.000000     ...      0.012497  0.000000   0.0   0.0  0.000000        0.0   \n",
       "4  0.000000     ...      0.000000  0.000000   0.0   0.0  0.000000        0.0   \n",
       "\n",
       "      youth  youthful  zay  zeal   zealand  zealous  zodiac  zone  zoological  \n",
       "0  0.003808  0.000000  0.0   0.0  0.008407      0.0     0.0   0.0         0.0  \n",
       "1  0.000000  0.000000  0.0   0.0  0.000000      0.0     0.0   0.0         0.0  \n",
       "2  0.000000  0.000000  0.0   0.0  0.013596      0.0     0.0   0.0         0.0  \n",
       "3  0.000000  0.000000  0.0   0.0  0.000000      0.0     0.0   0.0         0.0  \n",
       "4  0.057411  0.016667  0.0   0.0  0.000000      0.0     0.0   0.0         0.0  \n",
       "\n",
       "[5 rows x 10560 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(train_tfidf.toarray())\n",
    "tfidf_df.columns = vectorizer.get_feature_names()\n",
    "tfidf_df['text'] = train_df.text\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:41:56.081269Z",
     "start_time": "2019-02-22T05:41:55.214258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD data reducer.  We are going to reduce the feature space from 10560 to 112\n",
    "svd = TruncatedSVD(112)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "train_lsa = lsa.fit_transform(train_tfidf)\n",
    "test_lsa = lsa.transform(test_tfidf)\n",
    "\n",
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T20:13:23.375998Z",
     "start_time": "2019-02-22T20:13:23.155124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f3aee9c240>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(svd.explained_variance_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T20:10:54.381703Z",
     "start_time": "2019-02-22T20:10:54.252777Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0:\n",
      " whale      0.418823\n",
      "ahab       0.237918\n",
      "ship       0.196321\n",
      "ye         0.153166\n",
      "thou       0.149230\n",
      "captain    0.146746\n",
      "boat       0.130844\n",
      "syme       0.124313\n",
      "thee       0.110035\n",
      "stubb      0.109142\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Component 1:\n",
      " syme         0.499301\n",
      "anne         0.237729\n",
      "mrs          0.153786\n",
      "elliot       0.147307\n",
      "professor    0.138814\n",
      "gregory      0.135124\n",
      "wentworth    0.095746\n",
      "lady         0.085715\n",
      "charles      0.084928\n",
      "louisa       0.082219\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Component 2:\n",
      " anne         0.402980\n",
      "elliot       0.251585\n",
      "mrs          0.244615\n",
      "wentworth    0.169203\n",
      "captain      0.150750\n",
      "charles      0.147195\n",
      "musgrove     0.139707\n",
      "russell      0.132830\n",
      "mary         0.125773\n",
      "lady         0.121187\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Component 3:\n",
      " thee      0.160144\n",
      "song      0.144689\n",
      "thy       0.144080\n",
      "thou      0.139110\n",
      "city      0.135670\n",
      "macb      0.103898\n",
      "war       0.090611\n",
      "poem      0.086646\n",
      "states    0.085110\n",
      "haue      0.076179\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Component 4:\n",
      " macb       0.476569\n",
      "haue       0.343775\n",
      "th         0.182291\n",
      "vs         0.179934\n",
      "macd       0.178191\n",
      "macbeth    0.176917\n",
      "vpon       0.172669\n",
      "thou       0.146963\n",
      "banquo     0.132781\n",
      "hath       0.130139\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "Component 5:\n",
      " alice       0.497324\n",
      "susan       0.419810\n",
      "attorney    0.132153\n",
      "arthur      0.123180\n",
      "jem         0.120264\n",
      "guinea      0.113878\n",
      "mouse       0.107531\n",
      "rabbit      0.101443\n",
      "hal         0.099213\n",
      "king        0.092112\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "Component 6:\n",
      " alice          0.650019\n",
      "mouse          0.130708\n",
      "rabbit         0.128129\n",
      "turtle         0.116981\n",
      "gryphon        0.116006\n",
      "king           0.098198\n",
      "anne           0.092378\n",
      "caterpillar    0.090751\n",
      "mock           0.086484\n",
      "queen          0.078859\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "Component 7:\n",
      " whale        0.515590\n",
      "sperm        0.143018\n",
      "leviathan    0.092574\n",
      "macb         0.090662\n",
      "haue         0.062340\n",
      "cook         0.048339\n",
      "city         0.046563\n",
      "whales       0.042056\n",
      "poem         0.040754\n",
      "blubber      0.040586\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "Component 8:\n",
      " susan       0.492889\n",
      "attorney    0.120527\n",
      "anne        0.103844\n",
      "somers      0.094136\n",
      "lamb        0.093262\n",
      "price       0.091853\n",
      "barbara     0.090436\n",
      "hen         0.075930\n",
      "elliot      0.072502\n",
      "alice       0.067403\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "Component 9:\n",
      " hal            0.438142\n",
      "ben            0.319721\n",
      "gresham        0.195694\n",
      "maurice        0.153580\n",
      "uncle          0.137506\n",
      "uniform        0.132750\n",
      "arthur         0.126713\n",
      "archer         0.125566\n",
      "oakly          0.119305\n",
      "sweepstakes    0.107581\n",
      "Name: 9, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for the top 10 components, print out the top 10 lemmas that make up each component \n",
    "comp_df = pd.DataFrame(svd.components_, columns=vectorizer.get_feature_names())\n",
    "for i in range(10):\n",
    "    print('Component {}:\\n {}\\n'.format(i,comp_df.iloc[i].sort_values(ascending=False)[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component Notes:\n",
    "- Component 0:\n",
    "    - seems to be related to Moby Dick\n",
    "    - seafaring words\n",
    "    - 2nd word, 'ahab', is the main character of Moby Dick\n",
    "- Component 1:\n",
    "    - names and titles mostly from Persuasion\n",
    "- Component 2\n",
    "    - names and titles mostly from Persuasion\n",
    "- Component 3\n",
    "    - some shakespearian english words\n",
    "    - probably related to macbeth\n",
    "- Component 4\n",
    "    - similar to Component 3\n",
    "- Component 5\n",
    "    - seems to be related to alice and wonderland\n",
    "- Component 6\n",
    "    - similar to component 5\n",
    "    - animal words\n",
    "- Component 7\n",
    "    - combination of whale words (Moby Dick) and macbeth words\n",
    "- Component 8\n",
    "    - mostly names, unsure of which author they're from\n",
    "    - keys in on Edgeworth and Austen based on texts with highest component 8 value (below)\n",
    "- Component 9\n",
    "    - mostly names, unsure of which author most are from\n",
    "    - keys in on Edgeworth based on texts with highest component 9 value (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T20:52:51.441896Z",
     "start_time": "2019-02-22T20:52:51.435903Z"
    }
   },
   "outputs": [],
   "source": [
    "lsa_df = pd.DataFrame(train_lsa)\n",
    "lsa_df['author'] = train_df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T20:53:45.801379Z",
     "start_time": "2019-02-22T20:53:45.782393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.495245</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.464628</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.460690</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.290706</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.104827</td>\n",
       "      <td>Blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.090042</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.087961</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.087279</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.079011</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.078918</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            8     author\n",
       "77   0.495245  Edgeworth\n",
       "18   0.464628  Edgeworth\n",
       "73   0.460690  Edgeworth\n",
       "102  0.290706  Edgeworth\n",
       "46   0.104827      Blake\n",
       "52   0.090042     Austen\n",
       "81   0.087961     Austen\n",
       "101  0.087279     Austen\n",
       "20   0.079011     Austen\n",
       "61   0.078918     Austen"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_df.sort_values(by=8, ascending=False)[[8, 'author']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T20:54:19.294350Z",
     "start_time": "2019-02-22T20:54:19.278358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.628032</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.627512</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.582769</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.202646</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.141459</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.134996</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.085627</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.053962</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.051364</td>\n",
       "      <td>Edgeworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.042459</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            9     author\n",
       "75   0.628032  Edgeworth\n",
       "57   0.627512  Edgeworth\n",
       "27   0.582769  Edgeworth\n",
       "65   0.202646  Edgeworth\n",
       "108  0.141459  Edgeworth\n",
       "72   0.134996  Edgeworth\n",
       "102  0.085627  Edgeworth\n",
       "81   0.053962     Austen\n",
       "77   0.051364  Edgeworth\n",
       "52   0.042459     Austen"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_df.sort_values(by=9, ascending=False)[[9, 'author']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T21:29:13.283041Z",
     "start_time": "2019-02-22T21:29:12.978212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        0   8\n",
      "Blake         0   3\n",
      "Bryant        0   8\n",
      "Burgess       0   2\n",
      "Carroll       0   5\n",
      "Chesterton   11   0\n",
      "Edgeworth     0  26\n",
      "Melville      0  24\n",
      "Shakespeare   0   5\n",
      "Whitman       0  20 \n",
      "\n",
      "cluster       0   1\n",
      "author             \n",
      "Austen        0   8\n",
      "Blake         0   3\n",
      "Bryant        0   8\n",
      "Burgess       0   2\n",
      "Carroll       0   5\n",
      "Chesterton   11   0\n",
      "Edgeworth     0  26\n",
      "Melville      0  24\n",
      "Shakespeare   0   5\n",
      "Whitman       0  20 \n",
      "\n",
      "cluster       0   1\n",
      "author             \n",
      "Austen        0   8\n",
      "Blake         3   0\n",
      "Bryant        8   0\n",
      "Burgess       2   0\n",
      "Carroll       5   0\n",
      "Chesterton   11   0\n",
      "Edgeworth    26   0\n",
      "Melville      0  24\n",
      "Shakespeare   5   0\n",
      "Whitman      20   0 \n",
      "\n",
      "cluster       0   1\n",
      "author             \n",
      "Austen        8   0\n",
      "Blake         3   0\n",
      "Bryant        8   0\n",
      "Burgess       2   0\n",
      "Carroll       5   0\n",
      "Chesterton   11   0\n",
      "Edgeworth    26   0\n",
      "Melville      0  24\n",
      "Shakespeare   5   0\n",
      "Whitman      20   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 2\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:34:11.063623Z",
     "start_time": "2019-02-23T18:34:10.983669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        0   8\n",
      "Blake         0   3\n",
      "Bryant        0   8\n",
      "Burgess       0   2\n",
      "Carroll       0   5\n",
      "Chesterton    0  11\n",
      "Edgeworth     0  26\n",
      "Melville     24   0\n",
      "Shakespeare   0   5\n",
      "Whitman       0  20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "km = KMeans(n_clusters=n_clusters)\n",
    "km.fit(train_lsa)\n",
    "\n",
    "train_df['cluster'] = km.labels_\n",
    "\n",
    "print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:35:44.393807Z",
     "start_time": "2019-02-23T18:35:44.385797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 112), (112, 112))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lsa[train_df['cluster']==1].shape, train_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:38:12.031312Z",
     "start_time": "2019-02-23T18:38:12.023317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km2.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:37:51.368072Z",
     "start_time": "2019-02-23T18:37:51.357077Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     1\n",
       "14     1\n",
       "15     1\n",
       "16     1\n",
       "17     1\n",
       "18     1\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "31     1\n",
       "32     1\n",
       "34     1\n",
       "35     1\n",
       "      ..\n",
       "75     1\n",
       "76     1\n",
       "77     1\n",
       "78     1\n",
       "79     1\n",
       "81     1\n",
       "82     1\n",
       "83     1\n",
       "85     1\n",
       "86     1\n",
       "88     1\n",
       "89     1\n",
       "90     1\n",
       "92     1\n",
       "93     1\n",
       "94     1\n",
       "95     1\n",
       "97     1\n",
       "98     1\n",
       "99     1\n",
       "100    1\n",
       "101    1\n",
       "102    1\n",
       "103    1\n",
       "104    1\n",
       "106    1\n",
       "107    1\n",
       "108    1\n",
       "109    1\n",
       "110    1\n",
       "Name: cluster, Length: 88, dtype: int32"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['cluster']==1]['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:36:57.043985Z",
     "start_time": "2019-02-23T18:36:56.360376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        0   8\n",
      "Blake         0   3\n",
      "Bryant        0   8\n",
      "Burgess       0   2\n",
      "Carroll       0   5\n",
      "Chesterton    0  11\n",
      "Edgeworth     0  26\n",
      "Melville     24   0\n",
      "Shakespeare   0   5\n",
      "Whitman       0  20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "km2 = KMeans(n_clusters=n_clusters)\n",
    "km2.fit(train_lsa[train_df['cluster']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:49:36.121695Z",
     "start_time": "2019-02-23T18:48:38.684730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "c = 0 \n",
    "for i, cluster in enumerate(train_df['cluster']):   \n",
    "    if cluster != 0:\n",
    "        train_df['cluster'][i] = km2.labels_[c]+1\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:49:36.168635Z",
     "start_time": "2019-02-23T18:49:36.125662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2\n",
      "author                 \n",
      "Austen        0   0   8\n",
      "Blake         0   0   3\n",
      "Bryant        0   0   8\n",
      "Burgess       0   0   2\n",
      "Carroll       0   0   5\n",
      "Chesterton    0  11   0\n",
      "Edgeworth     0   0  26\n",
      "Melville     24   0   0\n",
      "Shakespeare   0   0   5\n",
      "Whitman       0   0  20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T18:53:17.417972Z",
     "start_time": "2019-02-23T18:52:30.532587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2   3\n",
      "author                     \n",
      "Austen        0   0   8   0\n",
      "Blake         0   0   0   3\n",
      "Bryant        0   0   6   2\n",
      "Burgess       0   0   2   0\n",
      "Carroll       0   0   5   0\n",
      "Chesterton    0  11   0   0\n",
      "Edgeworth     0   0  26   0\n",
      "Melville     24   0   0   0\n",
      "Shakespeare   0   0   0   5\n",
      "Whitman       0   0   0  20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "km2 = KMeans(n_clusters=n_clusters)\n",
    "km2.fit(train_lsa[train_df['cluster']==2])\n",
    "\n",
    "c = 0 \n",
    "for i, cluster in enumerate(train_df['cluster']):   \n",
    "    if cluster == 2:\n",
    "        train_df['cluster'][i] = km2.labels_[c]+2\n",
    "        c += 1\n",
    "\n",
    "print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- First 3 clustering attempts:\n",
    "    - one cluster made up entirely of Melville, or mostly of Melville plus one other author\n",
    "    - other cluster made up of remaining authors\n",
    "    - No authors split between clusters\n",
    "    \n",
    "- Last cluster attempt:\n",
    "    - one cluster all Chesterton, other cluster remaining\n",
    "    - No authors split between clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T08:46:22.266193Z",
     "start_time": "2019-01-13T08:46:22.257201Z"
    }
   },
   "outputs": [],
   "source": [
    "n_rows = len(train_lsa)\n",
    "n_samples = 2\n",
    "\n",
    "indexes = np.arange(n_rows)\n",
    "sample_indexes = np.random.choice(indexes, size=(n_samples, n_rows//n_samples), replace=False)\n",
    "\n",
    "samples = [train_lsa[sample_indexes[i]] for i in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T08:46:30.937687Z",
     "start_time": "2019-01-13T08:46:30.811216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0         0  1\n",
      "author            \n",
      "Austen        1  0\n",
      "Blake         2  0\n",
      "Bryant        2  0\n",
      "Carroll       2  0\n",
      "Chesterton    0  7\n",
      "Edgeworth    18  0\n",
      "Melville     11  0\n",
      "Shakespeare   5  0\n",
      "Whitman       8  0 \n",
      "\n",
      "col_0       0   1\n",
      "author           \n",
      "Austen      7   0\n",
      "Blake       0   1\n",
      "Bryant      0   6\n",
      "Burgess     0   2\n",
      "Carroll     0   3\n",
      "Chesterton  0   4\n",
      "Edgeworth   8   0\n",
      "Melville    0  13\n",
      "Whitman     0  12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "for i, sample in enumerate(samples):\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    km.fit(sample)\n",
    "    \n",
    "    print(pd.crosstab(train_df.iloc[sample_indexes[i]]['author'], km.labels_), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T03:09:55.066059Z",
     "start_time": "2019-02-22T03:09:54.388346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2   3  4\n",
      "author                        \n",
      "Austen        0   8   0   0  0\n",
      "Blake         0   0   3   0  0\n",
      "Bryant        0   0   8   0  0\n",
      "Burgess       0   0   2   0  0\n",
      "Carroll       0   0   5   0  0\n",
      "Chesterton   11   0   0   0  0\n",
      "Edgeworth     0  19   7   0  0\n",
      "Melville      0   0   1  23  0\n",
      "Shakespeare   0   0   0   0  5\n",
      "Whitman       0   0  20   0  0 \n",
      "\n",
      "cluster       0   1   2   3   4\n",
      "author                         \n",
      "Austen        0   8   0   0   0\n",
      "Blake         0   0   0   3   0\n",
      "Bryant        0   4   0   4   0\n",
      "Burgess       0   2   0   0   0\n",
      "Carroll       0   5   0   0   0\n",
      "Chesterton    0   0   0   0  11\n",
      "Edgeworth    14  12   0   0   0\n",
      "Melville      0   2  22   0   0\n",
      "Shakespeare   0   0   0   5   0\n",
      "Whitman       0   0   0  20   0 \n",
      "\n",
      "cluster       0   1   2   3  4\n",
      "author                        \n",
      "Austen        8   0   0   0  0\n",
      "Blake         0   0   0   3  0\n",
      "Bryant        1   0   0   6  1\n",
      "Burgess       1   0   0   0  1\n",
      "Carroll       0   0   0   0  5\n",
      "Chesterton    0  11   0   0  0\n",
      "Edgeworth    26   0   0   0  0\n",
      "Melville      0   0  24   0  0\n",
      "Shakespeare   0   0   0   5  0\n",
      "Whitman       0   0   0  20  0 \n",
      "\n",
      "cluster       0   1   2   3  4\n",
      "author                        \n",
      "Austen        0   8   0   0  0\n",
      "Blake         0   0   0   3  0\n",
      "Bryant        0   0   0   8  0\n",
      "Burgess       0   0   0   2  0\n",
      "Carroll       0   0   0   5  0\n",
      "Chesterton   11   0   0   0  0\n",
      "Edgeworth     0  24   0   2  0\n",
      "Melville      0   0  24   0  0\n",
      "Shakespeare   0   0   0   0  5\n",
      "Whitman       0   0   0  20  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 5\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T08:56:36.315421Z",
     "start_time": "2019-01-13T08:56:35.999602Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2   3   4\n",
      "author                         \n",
      "Austen        8   0   0   0   0\n",
      "Blake         0   0   0   0   3\n",
      "Bryant        0   0   3   0   5\n",
      "Burgess       0   0   2   0   0\n",
      "Carroll       0   0   5   0   0\n",
      "Chesterton    0  11   0   0   0\n",
      "Edgeworth    15   0  11   0   0\n",
      "Melville      0   0   5  19   0\n",
      "Shakespeare   0   0   0   0   5\n",
      "Whitman       0   0   0   0  20 \n",
      "\n",
      "cluster       0   1   2  3   4\n",
      "author                        \n",
      "Austen        0   8   0  0   0\n",
      "Blake         0   0   0  2   1\n",
      "Bryant        0   0   0  5   3\n",
      "Burgess       0   0   0  0   2\n",
      "Carroll       0   0   0  5   0\n",
      "Chesterton   11   0   0  0   0\n",
      "Edgeworth     0  15   0  4   7\n",
      "Melville      0   5  19  0   0\n",
      "Shakespeare   0   0   0  5   0\n",
      "Whitman       0   0   0  0  20 \n",
      "\n",
      "cluster       0   1  2   3   4\n",
      "author                        \n",
      "Austen        0   0  8   0   0\n",
      "Blake         0   3  0   0   0\n",
      "Bryant        0   8  0   0   0\n",
      "Burgess       0   2  0   0   0\n",
      "Carroll       0   3  0   0   2\n",
      "Chesterton    0   0  0  11   0\n",
      "Edgeworth     0   2  0   0  24\n",
      "Melville     24   0  0   0   0\n",
      "Shakespeare   0   5  0   0   0\n",
      "Whitman       0  20  0   0   0 \n",
      "\n",
      "cluster       0   1   2  3   4\n",
      "author                        \n",
      "Austen        8   0   0  0   0\n",
      "Blake         0   3   0  0   0\n",
      "Bryant        0   8   0  0   0\n",
      "Burgess       0   2   0  0   0\n",
      "Carroll       0   5   0  0   0\n",
      "Chesterton    0   0   0  0  11\n",
      "Edgeworth    14   6   0  6   0\n",
      "Melville      0   0  24  0   0\n",
      "Shakespeare   0   5   0  0   0\n",
      "Whitman       0  20   0  0   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 5\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Chesterton always got own cluster (and not split between clusters)\n",
    "- Authors split between clusters: Edgeworth(4/4), Bryant(2/4), Melvin (2/4), Blake(1/4), Carrol(1/4)\n",
    "- Authors never split between clusters: Austen, Chesterton, Shakespeare, Whitman, Burgess\n",
    "- Groups often in same cluster:\n",
    "    - Blake, Bryant, Whitman (4)\n",
    "    - Shakespeare, Blake, Bryant (3)\n",
    "    - Shakespeare, Whitman (3)\n",
    "    - Blake, Bryant, Burgess, Whitman (3)\n",
    "    - Austen, Edgeworth (3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:14:31.770841Z",
     "start_time": "2019-01-13T09:14:31.376361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2  3   4   5  6  7  8  9\n",
      "author                                        \n",
      "Austen        0   0   0  0   0   0  0  8  0  0\n",
      "Blake         0   0   0  0   0   3  0  0  0  0\n",
      "Bryant        2   0   0  0   0   4  1  0  0  1\n",
      "Burgess       0   0   0  0   0   0  0  0  0  2\n",
      "Carroll       0   0   0  0   0   0  5  0  0  0\n",
      "Chesterton    0   0  11  0   0   0  0  0  0  0\n",
      "Edgeworth    14   0   0  0   0   0  0  3  9  0\n",
      "Melville      0  12   0  0  12   0  0  0  0  0\n",
      "Shakespeare   0   0   0  5   0   0  0  0  0  0\n",
      "Whitman       0   0   0  0   0  20  0  0  0  0 \n",
      "\n",
      "cluster      0   1   2   3  4  5  6   7   8  9\n",
      "author                                        \n",
      "Austen       0   0   0   0  0  8  0   0   0  0\n",
      "Blake        0   0   0   3  0  0  0   0   0  0\n",
      "Bryant       0   0   0   7  0  0  1   0   0  0\n",
      "Burgess      0   0   0   0  0  0  0   0   2  0\n",
      "Carroll      0   0   0   0  0  0  5   0   0  0\n",
      "Chesterton   0   0  11   0  0  0  0   0   0  0\n",
      "Edgeworth    6   0   0   0  5  5  0   0  10  0\n",
      "Melville     0  12   0   0  0  0  0  12   0  0\n",
      "Shakespeare  0   0   0   0  0  0  0   0   0  5\n",
      "Whitman      0   0   0  20  0  0  0   0   0  0 \n",
      "\n",
      "cluster       0   1   2  3  4  5  6   7   8  9\n",
      "author                                        \n",
      "Austen        0   0   0  0  0  0  8   0   0  0\n",
      "Blake         0   3   0  0  0  0  0   0   0  0\n",
      "Bryant        1   7   0  0  0  0  0   0   0  0\n",
      "Burgess       2   0   0  0  0  0  0   0   0  0\n",
      "Carroll       1   4   0  0  0  0  0   0   0  0\n",
      "Chesterton    0   0   0  0  0  0  0   0  11  0\n",
      "Edgeworth    12   0   0  4  5  3  2   0   0  0\n",
      "Melville      0   0  13  0  0  0  0  11   0  0\n",
      "Shakespeare   0   0   0  0  0  0  0   0   0  5\n",
      "Whitman       0  20   0  0  0  0  0   0   0  0 \n",
      "\n",
      "cluster      0   1   2   3   4  5  6  7   8  9\n",
      "author                                        \n",
      "Austen       0   0   0   0   0  0  8  0   0  0\n",
      "Blake        0   3   0   0   0  0  0  0   0  0\n",
      "Bryant       0   6   0   0   0  0  0  1   0  1\n",
      "Burgess      0   0   0   0   0  0  0  0   2  0\n",
      "Carroll      0   0   0   0   0  5  0  0   0  0\n",
      "Chesterton   0   0  11   0   0  0  0  0   0  0\n",
      "Edgeworth    0   0   0   0   0  0  2  4  11  9\n",
      "Melville     0   0   0  13  11  0  0  0   0  0\n",
      "Shakespeare  5   0   0   0   0  0  0  0   0  0\n",
      "Whitman      0  20   0   0   0  0  0  0   0  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 10\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- All Chesterton always in exclusive cluster\n",
    "- All Shakespeare always in exclusive cluster\n",
    "- Melville always in 2 exclusive clusters\n",
    "- Interesting groupings:\n",
    "    - Blake, Bryant, Whitman (4)\n",
    "    - Austen, Edgeworth (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:19:10.308516Z",
     "start_time": "2019-01-13T09:19:09.760355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   0   0   0   0   0   0   1   1   0   0   1   0   4   0   0   \n",
      "Burgess       0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Carroll       0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   \n",
      "Chesterton    0  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Edgeworth     0   0   0   5   0   4   0   0   0   4   4   2   0   1   4   0   \n",
      "Melville      9   0   0   0   3   0   0   0   0   0   0   0  10   0   0   0   \n",
      "Shakespeare   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Whitman       0   0   0   0   0   0   3  17   0   0   0   0   0   0   0   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        0   0   0   0  \n",
      "Blake         3   0   0   0  \n",
      "Bryant        1   0   0   0  \n",
      "Burgess       0   0   2   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   0   0  \n",
      "Edgeworth     0   2   0   0  \n",
      "Melville      0   0   0   2  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n",
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   \n",
      "Burgess       0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Carroll       0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0   \n",
      "Chesterton    0   0   0   0   7   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Edgeworth     0   2   0   0   0   2   4   4   3   1   0   4   0   3   0   3   \n",
      "Melville      0   0   0   7   0   0   0   0   0   0   0   0   8   0   0   0   \n",
      "Shakespeare   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Whitman       0   0  10   0   0   0   0   0   0   0  10   0   0   0   0   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        0   0   0   0  \n",
      "Blake         0   3   0   0  \n",
      "Bryant        0   1   5   0  \n",
      "Burgess       0   0   2   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    4   0   0   0  \n",
      "Edgeworth     0   0   0   0  \n",
      "Melville      0   0   0   9  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n",
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   0   0   1   0   0   0   0   1   0   1   0   1   0   0   1   \n",
      "Burgess       0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   \n",
      "Carroll       0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   \n",
      "Chesterton    0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Edgeworth     4   0   0   0   2   0   1   0   0   4   0   2   3   5   2   0   \n",
      "Melville      0  10   0   0   0   0   0  10   0   0   0   0   0   0   0   0   \n",
      "Shakespeare   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   \n",
      "Whitman       0   0   0  11   0   0   0   0   0   0   0   0   0   0   0   9   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        0   0   0   0  \n",
      "Blake         3   0   0   0  \n",
      "Bryant        3   0   0   0  \n",
      "Burgess       0   0   0   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   0   0  \n",
      "Edgeworth     0   2   1   0  \n",
      "Melville      0   0   0   4  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n",
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   0   0   0   0   0   0   0   0   0   4   3   0   0   0   0   \n",
      "Burgess       0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   \n",
      "Carroll       0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Chesterton    0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Edgeworth     0   0   0   0   4   4   3   6   0   0   0   0   2   2   0   0   \n",
      "Melville      0  15   0   0   0   0   0   0   0   0   0   0   0   0   0   9   \n",
      "Shakespeare   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   \n",
      "Whitman       6   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        8   0   0   0  \n",
      "Blake         0   3   0   0  \n",
      "Bryant        0   0   0   1  \n",
      "Burgess       0   0   0   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   0   0  \n",
      "Edgeworth     2   0   3   0  \n",
      "Melville      0   0   0   0  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   6   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 20\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:47:47.064891Z",
     "start_time": "2019-01-13T09:47:46.131242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        8   0\n",
      "Blake         3   0\n",
      "Bryant        8   0\n",
      "Burgess       2   0\n",
      "Carroll       5   0\n",
      "Chesterton   11   0\n",
      "Edgeworth    26   0\n",
      "Melville      2  22\n",
      "Shakespeare   5   0\n",
      "Whitman      20   0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        0   8\n",
      "Blake         0   3\n",
      "Bryant        0   8\n",
      "Burgess       0   2\n",
      "Carroll       0   5\n",
      "Chesterton    0  11\n",
      "Edgeworth     0  26\n",
      "Melville     22   2\n",
      "Shakespeare   0   5\n",
      "Whitman       0  20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        8   0\n",
      "Blake         3   0\n",
      "Bryant        8   0\n",
      "Burgess       2   0\n",
      "Carroll       5   0\n",
      "Chesterton   11   0\n",
      "Edgeworth    26   0\n",
      "Melville      2  22\n",
      "Shakespeare   5   0\n",
      "Whitman      20   0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1\n",
      "author             \n",
      "Austen        8   0\n",
      "Blake         3   0\n",
      "Bryant        8   0\n",
      "Burgess       2   0\n",
      "Carroll       5   0\n",
      "Chesterton   11   0\n",
      "Edgeworth    26   0\n",
      "Melville      2  22\n",
      "Shakespeare   5   0\n",
      "Whitman      20   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 2\n",
    "    km = SpectralClustering(n_clusters=n_clusters, affinity='rbf')\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- one cluster made up mostly or entirely of Melville, Other cluster = everything else\n",
    "- Melville split into 22 and 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:31:10.412468Z",
     "start_time": "2019-01-13T09:31:09.967131Z"
    },
    "code_folding": [
     6
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2  3  4\n",
      "author                       \n",
      "Austen        0   0   0  0  8\n",
      "Blake         3   0   0  0  0\n",
      "Bryant        8   0   0  0  0\n",
      "Burgess       2   0   0  0  0\n",
      "Carroll       5   0   0  0  0\n",
      "Chesterton    0   0  11  0  0\n",
      "Edgeworth    26   0   0  0  0\n",
      "Melville      2  22   0  0  0\n",
      "Shakespeare   0   0   0  5  0\n",
      "Whitman      20   0   0  0  0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2  3  4\n",
      "author                       \n",
      "Austen        0   0   0  0  8\n",
      "Blake         3   0   0  0  0\n",
      "Bryant        8   0   0  0  0\n",
      "Burgess       2   0   0  0  0\n",
      "Carroll       5   0   0  0  0\n",
      "Chesterton    0  11   0  0  0\n",
      "Edgeworth    26   0   0  0  0\n",
      "Melville      2   0  22  0  0\n",
      "Shakespeare   0   0   0  5  0\n",
      "Whitman      20   0   0  0  0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1  2   3  4\n",
      "author                       \n",
      "Austen        0   0  0   0  8\n",
      "Blake         0   3  0   0  0\n",
      "Bryant        0   8  0   0  0\n",
      "Burgess       0   2  0   0  0\n",
      "Carroll       0   5  0   0  0\n",
      "Chesterton    0   0  0  11  0\n",
      "Edgeworth     0  26  0   0  0\n",
      "Melville     22   2  0   0  0\n",
      "Shakespeare   0   0  5   0  0\n",
      "Whitman       0  20  0   0  0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0   1   2  3  4\n",
      "author                       \n",
      "Austen        0   0   0  0  8\n",
      "Blake         3   0   0  0  0\n",
      "Bryant        8   0   0  0  0\n",
      "Burgess       2   0   0  0  0\n",
      "Carroll       5   0   0  0  0\n",
      "Chesterton    0  11   0  0  0\n",
      "Edgeworth    26   0   0  0  0\n",
      "Melville      2   0  22  0  0\n",
      "Shakespeare   0   0   0  5  0\n",
      "Whitman      20   0   0  0  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 5\n",
    "    km = SpectralClustering(n_clusters=n_clusters)\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- All Austen always in exclusive cluster\n",
    "- All Shakespeare always in exclusive cluster\n",
    "- All Chesterton always in exclusive cluster\n",
    "- 22/24 Melville always in exclusive cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:34:17.826705Z",
     "start_time": "2019-01-13T09:34:17.344977Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2  3  4   5  6  7   8   9\n",
      "author                                        \n",
      "Austen       0   0   0  0  8   0  0  0   0   0\n",
      "Blake        0   0   0  0  0   0  0  0   0   3\n",
      "Bryant       0   0   8  0  0   0  0  0   0   0\n",
      "Burgess      0   0   2  0  0   0  0  0   0   0\n",
      "Carroll      5   0   0  0  0   0  0  0   0   0\n",
      "Chesterton   0  11   0  0  0   0  0  0   0   0\n",
      "Edgeworth    0   0  19  4  0   0  3  0   0   0\n",
      "Melville     0   0   2  0  0  12  0  0  10   0\n",
      "Shakespeare  0   0   0  0  0   0  0  5   0   0\n",
      "Whitman      0   0   0  0  0   0  0  0   0  20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2   3  4  5  6  7   8   9\n",
      "author                                        \n",
      "Austen       0   0   0   0  8  0  0  0   0   0\n",
      "Blake        0   0   0   0  0  0  0  0   0   3\n",
      "Bryant       0   0   8   0  0  0  0  0   0   0\n",
      "Burgess      0   0   2   0  0  0  0  0   0   0\n",
      "Carroll      5   0   0   0  0  0  0  0   0   0\n",
      "Chesterton   0   0   0  11  0  0  0  0   0   0\n",
      "Edgeworth    0   0  19   0  0  4  3  0   0   0\n",
      "Melville     0  12   2   0  0  0  0  0  10   0\n",
      "Shakespeare  0   0   0   0  0  0  0  5   0   0\n",
      "Whitman      0   0   0   0  0  0  0  0   0  20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster       0  1  2   3  4   5  6   7  8   9\n",
      "author                                        \n",
      "Austen        0  0  0   0  0   0  0   0  8   0\n",
      "Blake         0  0  0   0  0   0  0   3  0   0\n",
      "Bryant        8  0  0   0  0   0  0   0  0   0\n",
      "Burgess       2  0  0   0  0   0  0   0  0   0\n",
      "Carroll       0  5  0   0  0   0  0   0  0   0\n",
      "Chesterton    0  0  0  11  0   0  0   0  0   0\n",
      "Edgeworth    19  0  0   0  3   0  4   0  0   0\n",
      "Melville      2  0  0   0  0  12  0   0  0  10\n",
      "Shakespeare   0  0  5   0  0   0  0   0  0   0\n",
      "Whitman       0  0  0   0  0   0  0  20  0   0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1  2  3  4   5   6  7   8   9\n",
      "author                                        \n",
      "Austen       0   0  0  8  0   0   0  0   0   0\n",
      "Blake        0   0  0  0  0   0   0  0   3   0\n",
      "Bryant       0   8  0  0  0   0   0  0   0   0\n",
      "Burgess      0   2  0  0  0   0   0  0   0   0\n",
      "Carroll      0   0  5  0  0   0   0  0   0   0\n",
      "Chesterton   0   0  0  0  0  11   0  0   0   0\n",
      "Edgeworth    4  19  0  0  0   0   0  3   0   0\n",
      "Melville     0   2  0  0  0   0  12  0   0  10\n",
      "Shakespeare  0   0  0  0  5   0   0  0   0   0\n",
      "Whitman      0   0  0  0  0   0   0  0  20   0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 10\n",
    "    km = SpectralClustering(n_clusters=n_clusters, affinity='rbf')\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "- Pretty good:\n",
    "    - 58/112 texts in exclusive clusters\n",
    "- Edgeworth always split\n",
    "- Melville always split, but most end up in exclusive clusters\n",
    "- Blake and Whitman always in same cluster\n",
    "- Bryant, Burgess, and most of Edgeworth always in same cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:45:44.093152Z",
     "start_time": "2019-01-13T09:45:44.086152Z"
    }
   },
   "outputs": [],
   "source": [
    "n_rows = len(train_lsa)\n",
    "n_samples = 2\n",
    "\n",
    "indexes = np.arange(n_rows)\n",
    "sample_indexes = np.random.choice(indexes, size=(n_samples, n_rows//n_samples), replace=False)\n",
    "\n",
    "samples = [train_lsa[sample_indexes[i]] for i in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:45:46.497427Z",
     "start_time": "2019-01-13T09:45:46.307614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0        0   1  2  3  4  5  6  7  8  9\n",
      "author                                    \n",
      "Austen       0   0  0  0  0  0  0  0  0  3\n",
      "Blake        1   0  0  0  0  0  0  0  0  0\n",
      "Bryant       5   0  0  0  0  0  0  0  0  0\n",
      "Burgess      1   0  0  0  0  0  0  0  0  0\n",
      "Carroll      0   0  0  0  0  0  5  0  0  0\n",
      "Chesterton   0   0  0  6  0  0  0  0  0  0\n",
      "Edgeworth    7   0  2  0  0  0  0  0  2  0\n",
      "Melville     1   0  0  0  4  4  0  0  0  0\n",
      "Shakespeare  0   0  0  0  0  0  0  4  0  0\n",
      "Whitman      0  11  0  0  0  0  0  0  0  0 \n",
      "\n",
      "col_0        0  1  2  3  4  5  6  7  8  9\n",
      "author                                   \n",
      "Austen       0  0  0  0  0  0  5  0  0  0\n",
      "Blake        0  2  0  0  0  0  0  0  0  0\n",
      "Bryant       0  3  0  0  0  0  0  0  0  0\n",
      "Burgess      0  1  0  0  0  0  0  0  0  0\n",
      "Chesterton   0  0  5  0  0  0  0  0  0  0\n",
      "Edgeworth    2  5  0  2  2  2  0  0  2  0\n",
      "Melville     0  1  0  0  0  0  0  7  0  7\n",
      "Shakespeare  0  1  0  0  0  0  0  0  0  0\n",
      "Whitman      0  9  0  0  0  0  0  0  0  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 10\n",
    "for i, sample in enumerate(samples):\n",
    "    km = SpectralClustering(n_clusters=n_clusters)\n",
    "    km.fit(sample)\n",
    "    \n",
    "    print(pd.crosstab(train_df.iloc[sample_indexes[i]]['author'], km.labels_), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:38:41.225520Z",
     "start_time": "2019-01-13T09:38:40.607874Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   8   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Burgess       0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   \n",
      "Carroll       0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   \n",
      "Chesterton    0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   \n",
      "Edgeworth     0   0   3   0   0   0   0   0   3   2   0   0   2   4   2   2   \n",
      "Melville      0   0   0   0   8   0  11   0   0   0   0   3   0   0   0   0   \n",
      "Shakespeare   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Whitman      20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        0   0   0   0  \n",
      "Blake         3   0   0   0  \n",
      "Bryant        0   0   8   0  \n",
      "Burgess       0   0   0   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   0   3  \n",
      "Edgeworth     0   2   6   0  \n",
      "Melville      0   0   2   0  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   0   \n",
      "Burgess       0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   \n",
      "Carroll       0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0   \n",
      "Chesterton    0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0   \n",
      "Edgeworth     0   2   0   0   2   6   0   0   4   2   0   0   3   2   3   2   \n",
      "Melville     11   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   \n",
      "Shakespeare   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Whitman       0   0   0  20   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        0   0   0   0  \n",
      "Blake         0   0   0   3  \n",
      "Bryant        0   0   0   0  \n",
      "Burgess       0   0   0   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   3   0  \n",
      "Edgeworth     0   0   0   0  \n",
      "Melville      8   3   0   0  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Burgess       0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   \n",
      "Carroll       5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Chesterton    0   0   3   0   0   0   0   0   0   0   0   0   0   0   8   0   \n",
      "Edgeworth     0   6   0   0   2   2   2   0   3   3   4   0   2   0   0   0   \n",
      "Melville      0   2   0   0   0   0   0   0   0   0   0   0   0   8   0  11   \n",
      "Shakespeare   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   \n",
      "Whitman       0   0   0  20   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        8   0   0   0  \n",
      "Blake         0   0   3   0  \n",
      "Bryant        0   0   0   0  \n",
      "Burgess       0   0   0   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   0   0  \n",
      "Edgeworth     0   2   0   0  \n",
      "Melville      0   0   0   3  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
      "author                                                                        \n",
      "Austen        0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   \n",
      "Blake         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Bryant        0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Burgess       0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   \n",
      "Carroll       0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "Chesterton    0   0   0   8   0   0   0   0   0   0   0   0   0   3   0   0   \n",
      "Edgeworth     3   6   0   0   4   0   2   0   0   2   3   2   2   0   0   0   \n",
      "Melville      0   2   0   0   0   0   0   0   8   0   0   0   0   0   0   0   \n",
      "Shakespeare   0   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   \n",
      "Whitman       0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   \n",
      "\n",
      "cluster      16  17  18  19  \n",
      "author                       \n",
      "Austen        0   0   0   0  \n",
      "Blake         0   0   0   3  \n",
      "Bryant        0   0   0   0  \n",
      "Burgess       0   0   0   0  \n",
      "Carroll       0   0   0   0  \n",
      "Chesterton    0   0   0   0  \n",
      "Edgeworth     2   0   0   0  \n",
      "Melville      0  11   3   0  \n",
      "Shakespeare   0   0   0   0  \n",
      "Whitman       0   0   0   0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    n_clusters = 20\n",
    "    km = SpectralClustering(n_clusters=n_clusters, affinity='rbf')\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- 98/112 texts in exclusive clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T20:16:10.425467Z",
     "start_time": "2019-02-23T20:16:10.407477Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.random' has no attribute 'bin_seeding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-b41c1055cd65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeanShift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbin_seeding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_lsa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'bin_seeding'"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    km = MeanShift()\n",
    "    km.fit(train_lsa)\n",
    "\n",
    "    train_df['cluster'] = km.labels_\n",
    "\n",
    "    print(pd.crosstab(train_df['author'], train_df['cluster']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T07:02:59.345143Z",
     "start_time": "2019-01-13T07:02:59.338142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T03:10:54.743397Z",
     "start_time": "2019-02-22T03:10:54.737401Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T22:47:36.443918Z",
     "start_time": "2019-02-22T22:47:36.380936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cluster</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cluster      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
       "author                                                                        \n",
       "Austen        0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   \n",
       "Blake         0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   \n",
       "Bryant        0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   1   \n",
       "Burgess       0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   \n",
       "Carroll       0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "Chesterton    0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   \n",
       "Edgeworth     0   0   4   0   0   3   0   4   0   0   2   0   0   4   0   0   \n",
       "Melville     11   0   0   0   0   0   0   0   0   4   0   0   0   0   9   0   \n",
       "Shakespeare   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   \n",
       "Whitman       0   0   0   0   0   0   0   0  12   0   0   0   0   0   0   8   \n",
       "\n",
       "cluster      16  17  18  19  20  \n",
       "author                           \n",
       "Austen        0   0   0   0   0  \n",
       "Blake         0   0   0   0   0  \n",
       "Bryant        0   0   0   0   4  \n",
       "Burgess       0   0   0   0   0  \n",
       "Carroll       0   0   0   0   0  \n",
       "Chesterton    0   0   0   8   0  \n",
       "Edgeworth     2   3   4   0   0  \n",
       "Melville      0   0   0   0   0  \n",
       "Shakespeare   0   0   0   0   0  \n",
       "Whitman       0   0   0   0   0  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = AffinityPropagation()\n",
    "km.fit(train_lsa)\n",
    "\n",
    "train_df['cluster'] = km.labels_\n",
    "\n",
    "cluster_df = pd.crosstab(train_df['author'], train_df['cluster'])\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T21:54:44.712548Z",
     "start_time": "2019-02-22T21:54:44.660575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edgeworth      12\n",
       "Whitman         5\n",
       "Bryant          4\n",
       "Melville        4\n",
       "Carroll         4\n",
       "Austen          3\n",
       "Chesterton      2\n",
       "Shakespeare     2\n",
       "Burgess         1\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T22:47:52.655446Z",
     "start_time": "2019-02-22T22:47:52.595483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0   1   2   3   4   5   6   7   8   10  13  16  17  19  20\n",
       "author                                                                 \n",
       "Austen        0   0   0   0   0   0   0   0   0   3   0   0   0   0   0\n",
       "Bryant        0   0   0   2   0   0   0   0   0   0   0   0   0   0   2\n",
       "Burgess       0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
       "Carroll       0   4   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "Chesterton    0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
       "Edgeworth     0   0   1   0   0   1   0   1   0   3   2   3   1   0   0\n",
       "Melville      4   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "Shakespeare   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
       "Whitman       0   0   0   0   0   0   0   0   5   0   0   0   0   0   0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test_df['author'], km.predict(test_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T22:47:58.128863Z",
     "start_time": "2019-02-22T22:47:58.116870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Melville',\n",
       " 1: 'Carroll',\n",
       " 2: 'Edgeworth',\n",
       " 3: 'Bryant',\n",
       " 4: 'Shakespeare',\n",
       " 5: 'Edgeworth',\n",
       " 6: 'Burgess',\n",
       " 7: 'Edgeworth',\n",
       " 8: 'Whitman',\n",
       " 9: 'Melville',\n",
       " 10: 'Austen',\n",
       " 11: 'Blake',\n",
       " 12: 'Chesterton',\n",
       " 13: 'Edgeworth',\n",
       " 14: 'Melville',\n",
       " 15: 'Whitman',\n",
       " 16: 'Edgeworth',\n",
       " 17: 'Edgeworth',\n",
       " 18: 'Edgeworth',\n",
       " 19: 'Chesterton',\n",
       " 20: 'Bryant'}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name each cluster based on author most represented by cluster and save in dictionary\n",
    "cluster_names = {}\n",
    "for i in range(21):\n",
    "    col = cluster_df[i]\n",
    "    cluster_name = col.idxmax()\n",
    "\n",
    "    cluster_names[i] = cluster_name\n",
    "cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T22:48:01.875115Z",
     "start_time": "2019-02-22T22:48:01.844136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 34/37, 0.918918918918919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>cluster_pred</th>\n",
       "      <th>correct_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Austen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Austen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austen</td>\n",
       "      <td>Austen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bryant</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bryant</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bryant</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bryant</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Burgess</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chesterton</td>\n",
       "      <td>Chesterton</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chesterton</td>\n",
       "      <td>Chesterton</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Austen</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Austen</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Edgeworth</td>\n",
       "      <td>Austen</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Melville</td>\n",
       "      <td>Melville</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Melville</td>\n",
       "      <td>Melville</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Melville</td>\n",
       "      <td>Melville</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Melville</td>\n",
       "      <td>Melville</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Whitman</td>\n",
       "      <td>Whitman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Whitman</td>\n",
       "      <td>Whitman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Whitman</td>\n",
       "      <td>Whitman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Whitman</td>\n",
       "      <td>Whitman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Whitman</td>\n",
       "      <td>Whitman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author cluster_pred  correct_pred\n",
       "0        Austen       Austen          True\n",
       "1        Austen       Austen          True\n",
       "2        Austen       Austen          True\n",
       "3        Bryant       Bryant          True\n",
       "4        Bryant       Bryant          True\n",
       "5        Bryant       Bryant          True\n",
       "6        Bryant       Bryant          True\n",
       "7       Burgess      Burgess          True\n",
       "8       Carroll      Carroll          True\n",
       "9       Carroll      Carroll          True\n",
       "10      Carroll      Carroll          True\n",
       "11      Carroll      Carroll          True\n",
       "12   Chesterton   Chesterton          True\n",
       "13   Chesterton   Chesterton          True\n",
       "14    Edgeworth    Edgeworth          True\n",
       "15    Edgeworth    Edgeworth          True\n",
       "16    Edgeworth    Edgeworth          True\n",
       "17    Edgeworth    Edgeworth          True\n",
       "18    Edgeworth    Edgeworth          True\n",
       "19    Edgeworth    Edgeworth          True\n",
       "20    Edgeworth       Austen         False\n",
       "21    Edgeworth       Austen         False\n",
       "22    Edgeworth    Edgeworth          True\n",
       "23    Edgeworth    Edgeworth          True\n",
       "24    Edgeworth    Edgeworth          True\n",
       "25    Edgeworth       Austen         False\n",
       "26     Melville     Melville          True\n",
       "27     Melville     Melville          True\n",
       "28     Melville     Melville          True\n",
       "29     Melville     Melville          True\n",
       "30  Shakespeare  Shakespeare          True\n",
       "31  Shakespeare  Shakespeare          True\n",
       "32      Whitman      Whitman          True\n",
       "33      Whitman      Whitman          True\n",
       "34      Whitman      Whitman          True\n",
       "35      Whitman      Whitman          True\n",
       "36      Whitman      Whitman          True"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test clusters, \n",
    "test_cluster_pred = [cluster_names[i] for i in km.predict(test_lsa)]\n",
    "test_df['cluster_pred'] =  test_cluster_pred\n",
    "test_df['correct_pred'] = test_df['author'] == test_df['cluster_pred']\n",
    "\n",
    "print('score: {}/{}, {}'.format(test_df.correct_pred.sum(), len(test_df), test_df.correct_pred.sum()/len(test_df)))\n",
    "test_df[['author', 'cluster_pred', 'correct_pred']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T05:58:25.568796Z",
     "start_time": "2019-01-15T05:58:25.534808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# fit and score NB just with bag of words counts\n",
    "nb = MultinomialNB()\n",
    "\n",
    "X = train_counts_matrix\n",
    "y = train_df['author']\n",
    "\n",
    "nb.fit(X, y)\n",
    "print('Training score: ', nb.score(X, y))\n",
    "print('Testing score: ', nb.score(test_counts_matrix, test_df['author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T23:50:38.811024Z",
     "start_time": "2019-02-22T23:50:38.793039Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Turn Bag of Words process into a class with fit and transform methods so we can use it in a pipeline\n",
    "# sklearn CountVectorizer does what we want (counts word occurences) \n",
    "# but the fit method in this class gets us the top n_words per author to pass to CountVectorizer\n",
    "class CountWords():\n",
    "    def __init__(self, n_words=1000):      \n",
    "        self.n_words = n_words\n",
    "        self.words = []\n",
    "        \n",
    "    def fit(self, texts, authors):\n",
    "        texts = list(texts)\n",
    "        \n",
    "        # get top n_words from each author using Count\n",
    "        for author in set(authors):\n",
    "            author_indices = [i for i, auth in enumerate(authors) if auth == author]\n",
    "            author_text = [texts[index] for index in author_indices]\n",
    "            cv = CountVectorizer(stop_words='english', lowercase=True, max_features=self.n_words)\n",
    "            cv.fit(author_text)        \n",
    "            self.words += cv.get_feature_names()\n",
    "        self.words = list(set(self.words))\n",
    "        \n",
    "    def transform(self, texts, authors=None):\n",
    "        cv = CountVectorizer(stop_words='english', lowercase=True, vocabulary=self.words)\n",
    "        return cv.transform(texts)\n",
    "    \n",
    "    def fit_transform(self, texts, authors):\n",
    "        self.fit(texts, authors)\n",
    "        return self.transform(texts, authors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:06:34.341850Z",
     "start_time": "2019-02-23T21:06:30.596992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val scores:  [1.         1.         0.95744681]\n"
     ]
    }
   ],
   "source": [
    "# with our CountWords class we can create a bag of words pipeline and use it in cross validation\n",
    "bow_nb = make_pipeline(CountWords(n_words=200), MultinomialNB())\n",
    "\n",
    "# words will now be baggged based on the training set in each fold of cross validation.\n",
    "\n",
    "cv = cross_val_score(bow_nb, df['lemmas'], df['author'], cv=3)\n",
    "print('cross val scores: ', cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
